# ZenOps LLM åŠŸèƒ½æµ‹è¯•æŒ‡å—

## æµ‹è¯•å‰å‡†å¤‡

### 1. ç¡®è®¤é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config.yml`,ç¡®ä¿ä»¥ä¸‹é…ç½®æ­£ç¡®:

```yaml
# LLM é…ç½®
llm:
  enabled: true
  provider: "deepseek"  # æˆ– openai, azure
  model: "deepseek-chat"
  api_key: "sk-your-api-key-here"  # æ›¿æ¢ä¸ºä½ çš„å®é™… API Key
  base_url: "https://api.deepseek.com"  # DeepSeek çš„ API åœ°å€

# é’‰é’‰é…ç½®
dingtalk:
  enabled: true
  mode: "stream"
  app_key: "your-app-key"
  app_secret: "your-app-secret"
  agent_id: "your-agent-id"

  # å¯ç”¨ LLM å¯¹è¯
  enable_llm_conversation: true

  # å¡ç‰‡é…ç½®(å¯é€‰)
  enable_stream_card: false  # å»ºè®®å…ˆæµ‹è¯•æ–‡æœ¬æ¨¡å¼
  card_template_id: ""       # æš‚ä¸é…ç½®
```

### 2. éªŒè¯æ—¥å¿—çº§åˆ«

ç¡®ä¿æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º `debug` ä»¥ä¾¿æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯:

```yaml
logging:
  level: "debug"
```

### 3. é‡æ–°ç¼–è¯‘å’Œå¯åŠ¨

```bash
# ç¼–è¯‘
make build

# æˆ–ç›´æ¥è¿è¡Œ
go build -o bin/zenops .

# å¯åŠ¨æœåŠ¡
./bin/zenops
```

## æµ‹è¯•æ­¥éª¤

### æµ‹è¯• 1: éªŒè¯ LLM åˆå§‹åŒ–

**é¢„æœŸæ—¥å¿—è¾“å‡º**:
```
INFO  LLM client initialized successfully
INFO  DingTalk stream handler initialized with LLM support
```

**å¦‚æœçœ‹åˆ°ä»¥ä¸‹æ—¥å¿—,è¯´æ˜é…ç½®æ­£ç¡®**:
```
DEBUG LLM config: provider=deepseek, model=deepseek-chat
```

### æµ‹è¯• 2: ç®€å•å¯¹è¯æµ‹è¯•

åœ¨é’‰é’‰ä¸­ @æœºå™¨äºº,å‘é€:
```
ä½ å¥½
```

**é¢„æœŸè¡Œä¸º**:
- ç»ˆç«¯æ—¥å¿—æ˜¾ç¤º: `Using LLM to process message`
- æœºå™¨äººè¿”å› LLM çš„å›å¤(ä¸è°ƒç”¨å·¥å…·)

**é¢„æœŸæ—¥å¿—**:
```
INFO  Using LLM to process message
DEBUG Processing LLM message: ä½ å¥½
DEBUG LLM response received (no tools called)
```

### æµ‹è¯• 3: å·¥å…·è°ƒç”¨æµ‹è¯•

åœ¨é’‰é’‰ä¸­å‘é€éœ€è¦æŸ¥è¯¢æ•°æ®çš„é—®é¢˜:
```
å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹é˜¿é‡Œäº‘æœ‰å¤šå°‘å° ECS æœåŠ¡å™¨
```

**é¢„æœŸè¡Œä¸º**:
1. æœºå™¨äººæ˜¾ç¤º "æ­£åœ¨æ€è€ƒä¸­..."
2. è°ƒç”¨ `aliyun_ecs_list` å·¥å…·
3. è¿”å›æŸ¥è¯¢ç»“æœå’Œåˆ†æ

**é¢„æœŸæ—¥å¿—**:
```
INFO  Using LLM to process message
DEBUG Processing LLM message: å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹é˜¿é‡Œäº‘æœ‰å¤šå°‘å° ECS æœåŠ¡å™¨
DEBUG LLM requesting tool call: aliyun_ecs_list
INFO  Calling MCP tool: aliyun_ecs_list
DEBUG Tool execution result: [...]
DEBUG LLM final response: æ ¹æ®æŸ¥è¯¢ç»“æœ...
```

### æµ‹è¯• 4: å¤šå·¥å…·è°ƒç”¨æµ‹è¯•

å‘é€éœ€è¦è°ƒç”¨å¤šä¸ªå·¥å…·çš„é—®é¢˜:
```
å¯¹æ¯”ä¸€ä¸‹é˜¿é‡Œäº‘å’Œè…¾è®¯äº‘çš„æœåŠ¡å™¨æ•°é‡
```

**é¢„æœŸè¡Œä¸º**:
1. LLM è°ƒç”¨ `aliyun_ecs_list`
2. LLM è°ƒç”¨ `tencent_cvm_list`
3. LLM ç»¼åˆåˆ†æå¹¶è¿”å›å¯¹æ¯”ç»“æœ

**é¢„æœŸæ—¥å¿—**:
```
DEBUG LLM requesting tool call: aliyun_ecs_list
INFO  Calling MCP tool: aliyun_ecs_list
DEBUG LLM requesting tool call: tencent_cvm_list
INFO  Calling MCP tool: tencent_cvm_list
DEBUG LLM final response: å¯¹æ¯”ç»“æœ...
```

### æµ‹è¯• 5: æµå¼å¡ç‰‡æµ‹è¯•(å¯é€‰)

å¦‚æœä½ å·²é…ç½®å¡ç‰‡æ¨¡æ¿ID,ç¼–è¾‘é…ç½®:
```yaml
dingtalk:
  enable_stream_card: true
  card_template_id: "your-template-id.schema"
```

é‡å¯æœåŠ¡å,å‘é€ç›¸åŒçš„é—®é¢˜,è§‚å¯Ÿå¡ç‰‡æ˜¯å¦å®æ—¶æ›´æ–°ã€‚

**é¢„æœŸæ—¥å¿—**:
```
DEBUG Creating stream card
INFO  Card created successfully, trackID: xxx
DEBUG Streaming update: 0/500 chars
DEBUG Streaming update: 500/1000 chars
DEBUG Streaming update: finalized
```

## å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1: æ—¥å¿—æ˜¾ç¤º "æ— æ³•ç†è§£æ‚¨çš„è¯·æ±‚"

**åŸå› **: LLM æœªè¢«è°ƒç”¨,ä»åœ¨ä½¿ç”¨æ„å›¾è§£æå™¨

**æ£€æŸ¥**:
```bash
# æŸ¥çœ‹æ—¥å¿—,åº”è¯¥çœ‹åˆ°:
INFO  Using LLM to process message

# å¦‚æœçœ‹åˆ°ä»¥ä¸‹å†…å®¹,è¯´æ˜ LLM æœªå¯ç”¨:
DEBUG Intent parsing result: unknown
```

**è§£å†³**:
- ç¡®è®¤ `config.yml` ä¸­ `llm.enabled: true`
- ç¡®è®¤ `dingtalk.enable_llm_conversation: true`
- é‡å¯æœåŠ¡

### é—®é¢˜ 2: LLM è°ƒç”¨å¤±è´¥

**é”™è¯¯æ—¥å¿—**:
```
ERROR Failed to call LLM: ...
```

**æ£€æŸ¥**:
1. API Key æ˜¯å¦æ­£ç¡®
2. Base URL æ˜¯å¦æ­£ç¡®
3. ç½‘ç»œæ˜¯å¦å¯è¾¾
4. API é¢åº¦æ˜¯å¦å……è¶³

**æµ‹è¯• API è¿æ¥**:
```bash
# DeepSeek æµ‹è¯•
curl https://api.deepseek.com/v1/models \
  -H "Authorization: Bearer sk-your-key"

# OpenAI æµ‹è¯•
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer sk-your-key"
```

### é—®é¢˜ 3: å·¥å…·æœªè¢«è°ƒç”¨

**ç—‡çŠ¶**: LLM å›å¤äº†é—®é¢˜,ä½†æ²¡æœ‰è°ƒç”¨å·¥å…·è·å–æ•°æ®

**åŸå› **:
1. æé—®ä¸å¤Ÿæ˜ç¡®
2. MCP å·¥å…·æœªæ³¨å†Œ
3. å·¥å…·å®šä¹‰ä¸æ¸…æ™°

**æ£€æŸ¥å·¥å…·åˆ—è¡¨**:
æŸ¥çœ‹å¯åŠ¨æ—¥å¿—ä¸­çš„å·¥å…·åˆ—è¡¨:
```
DEBUG Available MCP tools: [aliyun_ecs_list, tencent_cvm_list, ...]
```

**æ”¹è¿›æé—®**:
- âŒ "æœ‰å¤šå°‘æœåŠ¡å™¨?" (å¤ªæ¨¡ç³Š)
- âœ… "æŸ¥è¯¢é˜¿é‡Œäº‘ ECS åˆ—è¡¨" (æ˜ç¡®)
- âœ… "å¸®æˆ‘çœ‹çœ‹è…¾è®¯äº‘æœ‰å¤šå°‘å° CVM" (æ˜ç¡®)

### é—®é¢˜ 4: å¡ç‰‡åˆ›å»ºå¤±è´¥

**é”™è¯¯æ—¥å¿—**:
```
ERROR Failed to create card, fallback to text reply
```

**è§£å†³**:
- æ£€æŸ¥ `card_template_id` æ˜¯å¦æ­£ç¡®
- ç¡®è®¤åº”ç”¨æœ‰å¡ç‰‡æƒé™
- æš‚æ—¶ç¦ç”¨å¡ç‰‡: `enable_stream_card: false`

### é—®é¢˜ 5: å“åº”å¾ˆæ…¢

**åŸå› **: LLM API å»¶è¿Ÿæˆ–å·¥å…·æ‰§è¡Œæ—¶é—´é•¿

**ä¼˜åŒ–æ–¹æ¡ˆ**:
1. åˆ‡æ¢åˆ°å“åº”æ›´å¿«çš„ LLM æä¾›å•†
2. ä½¿ç”¨æµå¼å¡ç‰‡æå‡ä½“éªŒæ„Ÿ
3. æ£€æŸ¥å·¥å…·æ‰§è¡Œæ•ˆç‡

## éªŒè¯æˆåŠŸçš„æ ‡å¿—

âœ… **LLM åŠŸèƒ½æ­£å¸¸çš„æ ‡å¿—**:

1. æ—¥å¿—ä¸­çœ‹åˆ° `Using LLM to process message`
2. ç®€å•å¯¹è¯èƒ½æ­£å¸¸å›å¤
3. æ˜ç¡®çš„æŸ¥è¯¢è¯·æ±‚ä¼šè°ƒç”¨å¯¹åº”çš„ MCP å·¥å…·
4. å·¥å…·æ‰§è¡Œç»“æœè¢« LLM æ­£ç¡®å¤„ç†å’Œåˆ†æ
5. æœ€ç»ˆå›å¤å‡†ç¡®ä¸”è‡ªç„¶

âœ… **æµå¼æ›´æ–°æ­£å¸¸çš„æ ‡å¿—**:

1. å›å¤å†…å®¹é€æ­¥æ˜¾ç¤º(æ–‡æœ¬æ¨¡å¼)æˆ–å¡ç‰‡å®æ—¶æ›´æ–°
2. æ—¥å¿—ä¸­çœ‹åˆ° `Streaming update` è®°å½•
3. æœ€ç»ˆå†…å®¹å®Œæ•´

## æ€§èƒ½æŒ‡æ ‡

**æ­£å¸¸å“åº”æ—¶é—´**:
- ç®€å•å¯¹è¯: 2-5 ç§’
- å•å·¥å…·è°ƒç”¨: 5-10 ç§’
- å¤šå·¥å…·è°ƒç”¨: 10-20 ç§’

**å¦‚æœå“åº”æ—¶é—´è¿‡é•¿**:
- æ£€æŸ¥ LLM API å»¶è¿Ÿ
- æ£€æŸ¥å·¥å…·æ‰§è¡Œæ—¶é—´
- è€ƒè™‘ä¼˜åŒ–æˆ–ç¼“å­˜

## ä¸‹ä¸€æ­¥

æµ‹è¯•é€šè¿‡å,å¯ä»¥:
1. é…ç½®æµå¼å¡ç‰‡è·å¾—æ›´å¥½ä½“éªŒ
2. æ·»åŠ æ›´å¤š MCP å·¥å…·
3. ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯
4. é…ç½®æƒé™æ§åˆ¶
5. å¯ç”¨ä½¿ç”¨ç»Ÿè®¡

## è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜:
1. æŸ¥çœ‹å®Œæ•´æ—¥å¿—: `logging.level: "debug"`
2. æ£€æŸ¥é…ç½®æ–‡ä»¶: `config.yml`
3. å‚è€ƒæ–‡æ¡£:
   - [docs/QUICKSTART_LLM.md](./QUICKSTART_LLM.md)
   - [docs/DINGTALK_LLM.md](./DINGTALK_LLM.md)
   - [docs/CARD_TEMPLATE_OPTIONAL.md](./CARD_TEMPLATE_OPTIONAL.md)

---

ç¥æµ‹è¯•é¡ºåˆ©! ğŸ‰
